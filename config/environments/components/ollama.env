# ComfyUI component configurations
NAMESPACE=OLLAMA

[default]
HOST=0.0.0.0
PORT=11434
BASE_PORT=11434
PORT_INCREMENT=1
INSTANCES_PER_GPU=1
MAX_CONCURRENT_JOBS=1
GPU_MEMORY_FRACTION=0.9
MAX_LOADED_MODELS=10
TIMEOUT_SECONDS=300
RETRY_ATTEMPTS=3
REQUEST_TIMEOUT_MS=300000
INSTALL_TIMEOUT=600
MODEL_DOWNLOAD_TIMEOUT=1800

[localdev]
DEFAULT_MODEL=qwen3:0.6b
DEFAULT_MODELS=tinyllama:1.1b,qwen3:0.6b

[localtest]
DEFAULT_MODEL=
DEFAULT_MODELS=

[production]
DEFAULT_MODEL=qwen3:8b
DEFAULT_MODELS=qwen3:8b,gemma3:4b,llama3.1:8b