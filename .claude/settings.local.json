{
  "permissions": {
    "allow": [
      "Bash(ls:*)",
      "Bash(mv:*)",
      "Bash(grep:*)",
      "Bash(find:*)",
      "Bash(rg:*)",
      "Bash(redis-cli:*)",
      "Bash(pnpm docker:dev:local:*)",
      "Bash(docker compose:*)",
      "Bash(pnpm dev:*)",
      "Bash(curl:*)",
      "Bash(docker logs:*)",
      "Bash(pnpm install:*)",
      "Bash(docker exec:*)",
      "Bash(pnpm build:*)",
      "Bash(pnpm typecheck:*)",
      "Bash(pnpm lint:*)",
      "Bash(git commit:*)",
      "Bash(mkdir:*)",
      "Bash(touch:*)",
      "Bash(pnpm redis:functions:list:*)",
      "Bash(pnpm test:*)",
      "Bash(pnpm redis:functions:install:*)",
      "Bash(chmod:*)",
      "Bash(brew install:*)",
      "Bash(railway status:*)",
      "Bash(railway logs:*)",
      "Bash(railway variables:*)",
      "Bash(railway up:*)",
      "WebFetch(domain:redis.io)",
      "WebFetch(domain:docs.railway.app)",
      "Bash(REDISCLI_AUTH=hYMwSwJMmiJyZPOvEeUliKPdlPTOlgaZ redis-cli -h caboose.proxy.rlwy.net -p 58551 --user default ping)",
      "Bash(export REDIS_URL=\"redis://default:JQSoNVpIPsuaDQYicNvocglialxPrTjj@ballast.proxy.rlwy.net:30645\")",
      "Bash(REDIS_URL=\"redis://default:JQSoNVpIPsuaDQYicNvocglialxPrTjj@ballast.proxy.rlwy.net:30645\" pnpm redis:functions:list)",
      "Bash(pnpm format:*)",
      "Bash(REDIS_URL=\"redis://default:JQSoNVpIPsuaDQYicNvocglialxPrTjj@ballast.proxy.rlwy.net:30645\" pnpm redis:functions:install)",
      "Bash(REDIS_URL=\"redis://default:JQSoNVpIPsuaDQYicNvocglialxPrTjj@ballast.proxy.rlwy.net:30645\" pnpm redis:functions:test)",
      "Bash(REDIS_URL=\"redis://default:JQSoNVpIPsuaDQYicNvocglialxPrTjj@ballast.proxy.rlwy.net:30645\" node -e \"\nconst Redis = require(''ioredis'');\nconst redis = new Redis(process.env.REDIS_URL);\n\nasync function test() {\n  try {\n    console.log(''üîç Testing Redis connection...'');\n    \n    // Test basic connectivity\n    const pong = await redis.ping();\n    console.log(''‚úÖ PING response:'', pong);\n    \n    // Test basic set/get\n    await redis.set(''test:key'', ''hello world'');\n    const value = await redis.get(''test:key'');\n    console.log(''‚úÖ SET/GET test:'', value);\n    \n    // Test Redis info\n    const info = await redis.info(''server'');\n    const version = info.match(/redis_version:([^\\r\\n]+)/)?.[1];\n    console.log(''‚úÖ Redis version:'', version);\n    \n    // Test list operations\n    await redis.del(''test:list'');\n    await redis.lpush(''test:list'', ''item1'', ''item2'', ''item3'');\n    const listItems = await redis.lrange(''test:list'', 0, -1);\n    console.log(''‚úÖ List operations:'', listItems);\n    \n    // Test hash operations\n    await redis.del(''test:hash'');\n    await redis.hmset(''test:hash'', ''field1'', ''value1'', ''field2'', ''value2'');\n    const hashData = await redis.hgetall(''test:hash'');\n    console.log(''‚úÖ Hash operations:'', hashData);\n    \n    // Test sorted set operations\n    await redis.del(''test:zset'');\n    await redis.zadd(''test:zset'', 100, ''high-priority'', 50, ''medium-priority'', 10, ''low-priority'');\n    const zsetItems = await redis.zrevrange(''test:zset'', 0, -1, ''WITHSCORES'');\n    console.log(''‚úÖ Sorted set operations:'', zsetItems);\n    \n    // Clean up test data\n    await redis.del(''test:key'', ''test:list'', ''test:hash'', ''test:zset'');\n    console.log(''‚úÖ Cleanup completed'');\n    \n    await redis.quit();\n    console.log(''üéâ All Redis tests passed!'');\n  } catch (error) {\n    console.error(''‚ùå Redis test failed:'', error.message);\n    process.exit(1);\n  }\n}\n\ntest();\n\")",
      "Bash(REDIS_URL=\"redis://default:JQSoNVpIPsuaDQYicNvocglialxPrTjj@ballast.proxy.rlwy.net:30645\" node -e \"\nconst Redis = require(''ioredis'');\nconst redis = new Redis(process.env.REDIS_URL);\n\nasync function testJobQueue() {\n  try {\n    console.log(''üîç Testing job queue operations...'');\n    \n    // Test job submission\n    const jobId = ''test-job-'' + Date.now();\n    const jobData = {\n      id: jobId,\n      service_required: ''comfyui'',\n      priority: ''100'',\n      payload: JSON.stringify({ prompt: ''test image generation'' }),\n      requirements: JSON.stringify({\n        hardware: { gpu_memory_gb: 8 },\n        models: [''sdxl'']\n      }),\n      created_at: new Date().toISOString(),\n      status: ''pending'',\n      retry_count: ''0'',\n      max_retries: ''3''\n    };\n    \n    // Store job data\n    await redis.hmset(\\`job:${jobId}\\`, jobData);\n    await redis.zadd(''jobs:pending'', 100, jobId);\n    console.log(''‚úÖ Job submitted:'', jobId);\n    \n    // Test worker registration\n    const workerId = ''test-worker-'' + Date.now();\n    const workerData = {\n      id: workerId,\n      status: ''idle'',\n      capabilities: JSON.stringify({\n        services: [''comfyui''],\n        hardware: { gpu_memory_gb: 16, cpu_cores: 8 },\n        models: { comfyui: [''sdxl'', ''sd15''] }\n      }),\n      connected_at: new Date().toISOString(),\n      last_heartbeat: new Date().toISOString()\n    };\n    \n    await redis.hmset(\\`worker:${workerId}\\`, workerData);\n    await redis.sadd(''workers:active'', workerId);\n    console.log(''‚úÖ Worker registered:'', workerId);\n    \n    // Test job queue queries\n    const pendingJobs = await redis.zrevrange(''jobs:pending'', 0, -1, ''WITHSCORES'');\n    console.log(''‚úÖ Pending jobs:'', pendingJobs.slice(0, 4)); // Show first 2 jobs\n    \n    const activeWorkers = await redis.smembers(''workers:active'');\n    console.log(''‚úÖ Active workers:'', activeWorkers.slice(0, 3)); // Show first 3 workers\n    \n    // Test Redis function availability\n    try {\n      const functions = await redis.call(''FUNCTION'', ''LIST'');\n      const jobMatchingLib = functions.find(lib => lib.library_name === ''jobMatching'');\n      if (jobMatchingLib) {\n        console.log(''‚úÖ Redis functions available:'', jobMatchingLib.functions.map(f => f.name));\n      } else {\n        console.log(''‚ö†Ô∏è  No jobMatching library found'');\n      }\n    } catch (err) {\n      console.log(''‚ùå Redis functions not available:'', err.message);\n    }\n    \n    // Test pub/sub channels (briefly)\n    const subscriber = new Redis(process.env.REDIS_URL);\n    await subscriber.subscribe(''job_progress'', ''worker_status'');\n    console.log(''‚úÖ Pub/sub channels subscribed'');\n    \n    // Test publishing\n    await redis.publish(''job_progress'', JSON.stringify({\n      job_id: jobId,\n      status: ''assigned'',\n      progress: 0\n    }));\n    console.log(''‚úÖ Progress event published'');\n    \n    // Cleanup\n    await redis.del(\\`job:${jobId}\\`, \\`worker:${workerId}\\`);\n    await redis.zrem(''jobs:pending'', jobId);\n    await redis.srem(''workers:active'', workerId);\n    \n    await subscriber.quit();\n    await redis.quit();\n    console.log(''üéâ Job queue tests passed!'');\n    \n  } catch (error) {\n    console.error(''‚ùå Job queue test failed:'', error.message);\n    process.exit(1);\n  }\n}\n\ntestJobQueue();\n\")",
      "Bash(REDIS_URL=\"redis://default:JQSoNVpIPsuaDQYicNvocglialxPrTjj@ballast.proxy.rlwy.net:30645\" node -e \"\nconst Redis = require(''ioredis'');\nconst redis = new Redis(process.env.REDIS_URL);\n\nasync function testMatchingFunction() {\n  try {\n    console.log(''üîç Testing Redis function job matching...'');\n    \n    // Create a test job\n    const jobId = ''test-job-matching-'' + Date.now();\n    const jobData = {\n      id: jobId,\n      service_required: ''comfyui'',\n      priority: ''100'',\n      payload: JSON.stringify({ prompt: ''test generation'' }),\n      requirements: JSON.stringify({\n        hardware: { gpu_memory_gb: 8 },\n        models: [''sdxl'']\n      }),\n      created_at: new Date().toISOString(),\n      status: ''pending'',\n      retry_count: ''0'',\n      max_retries: ''3''\n    };\n    \n    // Add job to Redis\n    await redis.hmset(\\`job:${jobId}\\`, jobData);\n    await redis.zadd(''jobs:pending'', 100, jobId);\n    console.log(''‚úÖ Test job created:'', jobId);\n    \n    // Test with matching worker capabilities\n    const matchingWorker = {\n      worker_id: ''test-worker-matching'',\n      services: [''comfyui'', ''a1111''],\n      hardware: { \n        gpu_memory_gb: 16, \n        cpu_cores: 8, \n        ram_gb: 32 \n      },\n      models: { \n        comfyui: [''sdxl'', ''sd15''],\n        a1111: [''anything-v3''] \n      }\n    };\n    \n    // Call Redis function\n    const result = await redis.fcall(\n      ''findMatchingJob'',\n      0, // no keys\n      JSON.stringify(matchingWorker),\n      ''10'' // max jobs to scan\n    );\n    \n    if (result) {\n      const parsed = JSON.parse(result);\n      console.log(''‚úÖ Function found matching job:'', parsed.jobId);\n      console.log(''‚úÖ Job details:'', Object.keys(parsed.job));\n    } else {\n      console.log(''‚ö†Ô∏è  No matching job found'');\n    }\n    \n    // Test with non-matching worker\n    const nonMatchingWorker = {\n      worker_id: ''test-worker-no-match'',\n      services: [''a1111''], // doesn''t support comfyui\n      hardware: { gpu_memory_gb: 4 } // insufficient GPU memory\n    };\n    \n    const result2 = await redis.fcall(\n      ''findMatchingJob'',\n      0,\n      JSON.stringify(nonMatchingWorker),\n      ''10''\n    );\n    \n    if (!result2) {\n      console.log(''‚úÖ Function correctly rejected non-matching worker'');\n    } else {\n      console.log(''‚ö†Ô∏è  Function incorrectly matched job to incompatible worker'');\n    }\n    \n    // Check job status after claiming\n    const jobStatus = await redis.hgetall(\\`job:${jobId}\\`);\n    console.log(''‚úÖ Job status after matching:'', jobStatus.status || ''unknown'');\n    \n    // Cleanup\n    await redis.del(\\`job:${jobId}\\`);\n    await redis.zrem(''jobs:pending'', jobId);\n    \n    await redis.quit();\n    console.log(''üéâ Redis function tests completed!'');\n    \n  } catch (error) {\n    console.error(''‚ùå Redis function test failed:'', error.message);\n    console.error(''Stack:'', error.stack);\n    process.exit(1);\n  }\n}\n\ntestMatchingFunction();\n\")",
      "Bash(REDIS_URL=\"redis://default:JQSoNVpIPsuaDQYicNvocglialxPrTjj@ballast.proxy.rlwy.net:30645\" node -e \"\nconst Redis = require(''ioredis'');\nconst redis = new Redis(process.env.REDIS_URL);\n\nasync function testMatchingFunction() {\n  try {\n    console.log(''üîç Testing Redis function job matching...'');\n    \n    // Create a test job\n    const jobId = ''test-job-matching-'' + Date.now();\n    const jobData = {\n      id: jobId,\n      service_required: ''comfyui'',\n      priority: ''100'',\n      payload: JSON.stringify({ prompt: ''test generation'' }),\n      requirements: JSON.stringify({\n        hardware: { gpu_memory_gb: 8 },\n        models: [''sdxl'']\n      }),\n      created_at: new Date().toISOString(),\n      status: ''pending'',\n      retry_count: ''0'',\n      max_retries: ''3''\n    };\n    \n    // Add job to Redis\n    await redis.hmset(''job:'' + jobId, jobData);\n    await redis.zadd(''jobs:pending'', 100, jobId);\n    console.log(''‚úÖ Test job created:'', jobId);\n    \n    // Test with matching worker capabilities\n    const matchingWorker = {\n      worker_id: ''test-worker-matching'',\n      services: [''comfyui'', ''a1111''],\n      hardware: { \n        gpu_memory_gb: 16, \n        cpu_cores: 8, \n        ram_gb: 32 \n      },\n      models: { \n        comfyui: [''sdxl'', ''sd15''],\n        a1111: [''anything-v3''] \n      }\n    };\n    \n    // Call Redis function\n    const result = await redis.fcall(\n      ''findMatchingJob'',\n      0,\n      JSON.stringify(matchingWorker),\n      ''10''\n    );\n    \n    if (result) {\n      const parsed = JSON.parse(result);\n      console.log(''‚úÖ Function found matching job:'', parsed.jobId);\n    } else {\n      console.log(''‚ö†Ô∏è  No matching job found'');\n    }\n    \n    // Cleanup\n    await redis.del(''job:'' + jobId);\n    await redis.zrem(''jobs:pending'', jobId);\n    \n    await redis.quit();\n    console.log(''üéâ Redis function test completed!'');\n    \n  } catch (error) {\n    console.error(''‚ùå Redis function test failed:'', error.message);\n    process.exit(1);\n  }\n}\n\ntestMatchingFunction();\n\")",
      "Bash(REDIS_URL=\"redis://default:JQSoNVpIPsuaDQYicNvocglialxPrTjj@ballast.proxy.rlwy.net:30645\" node -e \"\nconst Redis = require(''ioredis'');\nconst redis = new Redis(process.env.REDIS_URL);\n\nasync function testJobLifecycle() {\n  try {\n    console.log(''üîç Testing complete job lifecycle...'');\n    \n    // Submit a job (simulate API call)\n    const jobId = ''lifecycle-test-'' + Date.now();\n    const job = {\n      id: jobId,\n      service_required: ''comfyui'',\n      priority: ''75'',\n      payload: JSON.stringify({\n        prompt: ''A beautiful landscape painting'',\n        width: 1024,\n        height: 1024\n      }),\n      requirements: JSON.stringify({\n        hardware: { gpu_memory_gb: 12 },\n        models: [''sdxl''],\n        performance: { max_duration_minutes: 10 }\n      }),\n      created_at: new Date().toISOString(),\n      status: ''pending'',\n      retry_count: ''0'',\n      max_retries: ''3'',\n      submitted_by: ''test-client''\n    };\n    \n    await redis.hmset(''job:'' + jobId, job);\n    await redis.zadd(''jobs:pending'', parseInt(job.priority), jobId);\n    console.log(''‚úÖ Job submitted to queue:'', jobId);\n    \n    // Register a worker (simulate worker startup)\n    const workerId = ''test-lifecycle-worker'';\n    const worker = {\n      id: workerId,\n      status: ''idle'',\n      capabilities: JSON.stringify({\n        services: [''comfyui''],\n        hardware: { \n          gpu_memory_gb: 16, \n          gpu_model: ''RTX 4090'',\n          cpu_cores: 8, \n          ram_gb: 32 \n        },\n        models: { \n          comfyui: [''sdxl'', ''sd15'', ''sdxl-turbo''] \n        },\n        performance: {\n          concurrent_jobs: 2,\n          avg_job_time_minutes: 5\n        }\n      }),\n      connected_at: new Date().toISOString(),\n      last_heartbeat: new Date().toISOString(),\n      total_jobs_completed: ''0''\n    };\n    \n    await redis.hmset(''worker:'' + workerId, worker);\n    await redis.sadd(''workers:active'', workerId);\n    console.log(''‚úÖ Worker registered:'', workerId);\n    \n    // Worker requests job using Redis function\n    const workerCaps = JSON.parse(worker.capabilities);\n    workerCaps.worker_id = workerId;\n    \n    const matchResult = await redis.fcall(\n      ''findMatchingJob'',\n      0,\n      JSON.stringify(workerCaps),\n      ''5''\n    );\n    \n    if (matchResult) {\n      const match = JSON.parse(matchResult);\n      console.log(''‚úÖ Worker claimed job:'', match.jobId);\n      \n      // Verify job was assigned\n      const assignedJob = await redis.hgetall(''job:'' + match.jobId);\n      console.log(''‚úÖ Job status:'', assignedJob.status);\n      console.log(''‚úÖ Assigned to worker:'', assignedJob.worker_id);\n      \n      // Simulate job progress\n      await redis.xadd(''progress:'' + match.jobId, ''*'',\n        ''job_id'', match.jobId,\n        ''worker_id'', workerId,\n        ''status'', ''processing'',\n        ''progress'', ''50'',\n        ''message'', ''Generating image...'',\n        ''timestamp'', new Date().toISOString()\n      );\n      console.log(''‚úÖ Progress update sent'');\n      \n      // Complete the job\n      await redis.hmset(''job:'' + match.jobId,\n        ''status'', ''completed'',\n        ''completed_at'', new Date().toISOString(),\n        ''result'', JSON.stringify({ image_url: ''https://example.com/result.png'' })\n      );\n      \n      await redis.hmset(''worker:'' + workerId,\n        ''status'', ''idle'',\n        ''current_job_id'', '''',\n        ''total_jobs_completed'', ''1''\n      );\n      \n      console.log(''‚úÖ Job completed successfully'');\n      \n    } else {\n      console.log(''‚ùå No job matched worker capabilities'');\n    }\n    \n    // Check final state\n    const finalJobState = await redis.hgetall(''job:'' + jobId);\n    const finalWorkerState = await redis.hgetall(''worker:'' + workerId);\n    \n    console.log(''üìä Final job status:'', finalJobState.status);\n    console.log(''üìä Final worker status:'', finalWorkerState.status);\n    console.log(''üìä Jobs completed by worker:'', finalWorkerState.total_jobs_completed);\n    \n    // Cleanup\n    await redis.del(''job:'' + jobId, ''worker:'' + workerId, ''progress:'' + jobId);\n    await redis.srem(''workers:active'', workerId);\n    await redis.zrem(''jobs:pending'', jobId);\n    \n    await redis.quit();\n    console.log(''üéâ Complete job lifecycle test passed!'');\n    \n  } catch (error) {\n    console.error(''‚ùå Job lifecycle test failed:'', error.message);\n    process.exit(1);\n  }\n}\n\ntestJobLifecycle();\n\")",
      "Bash(REDIS_URL=\"redis://default:JQSoNVpIPsuaDQYicNvocglialxPrTjj@ballast.proxy.rlwy.net:30645\" node -e \"\nconst Redis = require(''ioredis'');\nconst redis = new Redis(process.env.REDIS_URL);\n\nasync function debugMatching() {\n  try {\n    console.log(''üîç Debugging job matching...'');\n    \n    // Create simple job with minimal requirements\n    const jobId = ''debug-test-'' + Date.now();\n    const job = {\n      id: jobId,\n      service_required: ''comfyui'',\n      priority: ''100'',\n      payload: JSON.stringify({ test: true }),\n      requirements: JSON.stringify({\n        hardware: { gpu_memory_gb: 8 }\n      }),\n      created_at: new Date().toISOString(),\n      status: ''pending'',\n      retry_count: ''0'',\n      max_retries: ''3''\n    };\n    \n    await redis.hmset(''job:'' + jobId, job);\n    await redis.zadd(''jobs:pending'', 100, jobId);\n    console.log(''‚úÖ Simple job created:'', jobId);\n    \n    // Test with worker that should definitely match\n    const simpleWorker = {\n      worker_id: ''debug-worker'',\n      services: [''comfyui''],\n      hardware: { gpu_memory_gb: 16 }\n    };\n    \n    console.log(''üìã Worker capabilities:'', JSON.stringify(simpleWorker, null, 2));\n    console.log(''üìã Job requirements:'', job.requirements);\n    \n    const result = await redis.fcall(\n      ''findMatchingJob'',\n      0,\n      JSON.stringify(simpleWorker),\n      ''10''\n    );\n    \n    if (result) {\n      const parsed = JSON.parse(result);\n      console.log(''‚úÖ Match successful:'', parsed.jobId);\n    } else {\n      console.log(''‚ùå No match - checking Redis logs'');\n      \n      // Check pending jobs\n      const pending = await redis.zrevrange(''jobs:pending'', 0, -1);\n      console.log(''üìã Pending jobs:'', pending);\n      \n      // Check job data\n      const jobData = await redis.hgetall(''job:'' + jobId);\n      console.log(''üìã Job data keys:'', Object.keys(jobData));\n    }\n    \n    // Cleanup\n    await redis.del(''job:'' + jobId);\n    await redis.zrem(''jobs:pending'', jobId);\n    await redis.quit();\n    \n  } catch (error) {\n    console.error(''‚ùå Debug test failed:'', error.message);\n    process.exit(1);\n  }\n}\n\ndebugMatching();\n\")",
      "Bash(REDIS_URL=\"redis://default:JQSoNVpIPsuaDQYicNvocglialxPrTjj@ballast.proxy.rlwy.net:30645\" node -e \"\nconst Redis = require(''ioredis'');\nconst redis = new Redis(process.env.REDIS_URL);\n\nasync function checkQueueState() {\n  try {\n    console.log(''üîç Checking current queue state...'');\n    \n    // Check pending jobs\n    const pendingJobs = await redis.zrevrange(''jobs:pending'', 0, -1, ''WITHSCORES'');\n    console.log(''üìã Pending jobs ('' + (pendingJobs.length / 2) + ''):'', pendingJobs);\n    \n    // Check active workers\n    const activeWorkers = await redis.smembers(''workers:active'');\n    console.log(''üìã Active workers ('' + activeWorkers.length + ''):'', activeWorkers);\n    \n    // Check some job details\n    if (pendingJobs.length > 0) {\n      for (let i = 0; i < Math.min(pendingJobs.length, 4); i += 2) {\n        const jobId = pendingJobs[i];\n        const priority = pendingJobs[i + 1];\n        const jobData = await redis.hgetall(''job:'' + jobId);\n        console.log(''üìã Job '' + jobId + '' (priority: '' + priority + ''):'');\n        console.log(''   Service:'', jobData.service_required);\n        console.log(''   Status:'', jobData.status);\n        console.log(''   Requirements:'', jobData.requirements);\n      }\n    }\n    \n    // Check worker details\n    if (activeWorkers.length > 0) {\n      for (let i = 0; i < Math.min(activeWorkers.length, 2); i++) {\n        const workerId = activeWorkers[i];\n        const workerData = await redis.hgetall(''worker:'' + workerId);\n        console.log(''üìã Worker '' + workerId + '':'');\n        console.log(''   Status:'', workerData.status);\n        console.log(''   Services:'', workerData.capabilities ? JSON.parse(workerData.capabilities).services : ''unknown'');\n      }\n    }\n    \n    await redis.quit();\n    console.log(''üéâ Queue state check completed'');\n    \n  } catch (error) {\n    console.error(''‚ùå Queue state check failed:'', error.message);\n    process.exit(1);\n  }\n}\n\ncheckQueueState();\n\")",
      "Bash(REDIS_URL=\"redis://default:JQSoNVpIPsuaDQYicNvocglialxPrTjj@ballast.proxy.rlwy.net:30645\" node -e \"\nconst Redis = require(''ioredis'');\nconst redis = new Redis(process.env.REDIS_URL);\n\nasync function testCapabilityFiltering() {\n  try {\n    console.log(''üîç Testing capability-based job filtering...'');\n    \n    // Create jobs with different requirements\n    const jobs = [\n      {\n        id: ''job-gpu-high'',\n        service_required: ''comfyui'',\n        priority: ''100'',\n        requirements: JSON.stringify({\n          hardware: { gpu_memory_gb: 24 },\n          models: [''sdxl'']\n        })\n      },\n      {\n        id: ''job-gpu-medium'', \n        service_required: ''comfyui'',\n        priority: ''90'',\n        requirements: JSON.stringify({\n          hardware: { gpu_memory_gb: 12 },\n          models: [''sd15'']\n        })\n      },\n      {\n        id: ''job-simulation'',\n        service_required: ''simulation'',\n        priority: ''80'',\n        requirements: JSON.stringify({\n          hardware: { cpu_cores: 2 }\n        })\n      },\n      {\n        id: ''job-a1111'',\n        service_required: ''a1111'', \n        priority: ''70'',\n        requirements: JSON.stringify({\n          hardware: { gpu_memory_gb: 8 },\n          models: [''anything-v3'']\n        })\n      }\n    ];\n    \n    // Submit all jobs\n    for (const job of jobs) {\n      const jobData = {\n        ...job,\n        payload: JSON.stringify({ test: true }),\n        created_at: new Date().toISOString(),\n        status: ''pending'',\n        retry_count: ''0'',\n        max_retries: ''3''\n      };\n      \n      await redis.hmset(''job:'' + job.id, jobData);\n      await redis.zadd(''jobs:pending'', parseInt(job.priority), job.id);\n      console.log(''‚úÖ Job submitted:'', job.id, ''requires:'', job.service_required);\n    }\n    \n    // Test different worker types\n    const workers = [\n      {\n        name: ''High-End ComfyUI Worker'',\n        capabilities: {\n          worker_id: ''worker-high-end'',\n          services: [''comfyui''],\n          hardware: { gpu_memory_gb: 32, cpu_cores: 16 },\n          models: { comfyui: [''sdxl'', ''sd15'', ''sdxl-turbo''] }\n        }\n      },\n      {\n        name: ''Medium ComfyUI Worker'',\n        capabilities: {\n          worker_id: ''worker-medium'',\n          services: [''comfyui''],\n          hardware: { gpu_memory_gb: 16, cpu_cores: 8 },\n          models: { comfyui: [''sd15''] }\n        }\n      },\n      {\n        name: ''Simulation Worker'',\n        capabilities: {\n          worker_id: ''worker-sim'',\n          services: [''simulation''],\n          hardware: { cpu_cores: 4 }\n        }\n      },\n      {\n        name: ''A1111 Worker'',\n        capabilities: {\n          worker_id: ''worker-a1111'',\n          services: [''a1111''],\n          hardware: { gpu_memory_gb: 12 },\n          models: { a1111: [''anything-v3'', ''realistic-vision''] }\n        }\n      },\n      {\n        name: ''Low-End Worker'',\n        capabilities: {\n          worker_id: ''worker-low'',\n          services: [''comfyui''],\n          hardware: { gpu_memory_gb: 6 },\n          models: { comfyui: [''sd15''] }\n        }\n      }\n    ];\n    \n    // Test each worker against available jobs\n    for (const worker of workers) {\n      console.log(\\`\\nü§ñ Testing ${worker.name}...\\`);\n      \n      const result = await redis.fcall(\n        ''findMatchingJob'',\n        0,\n        JSON.stringify(worker.capabilities),\n        ''10''\n      );\n      \n      if (result) {\n        const match = JSON.parse(result);\n        console.log(\\`  ‚úÖ Matched job: ${match.jobId}\\`);\n        \n        // Check what job was matched\n        const jobData = await redis.hgetall(''job:'' + match.jobId);\n        console.log(\\`  üìã Job service: ${jobData.service_required}\\`);\n        console.log(\\`  üìã Job requirements: ${jobData.requirements}\\`);\n        \n        // Put job back for next test\n        if (jobData.status === ''assigned'') {\n          await redis.hmset(''job:'' + match.jobId, ''status'', ''pending'');\n          await redis.zadd(''jobs:pending'', parseInt(jobData.priority || ''50''), match.jobId);\n        }\n      } else {\n        console.log(''  ‚ùå No matching job found'');\n      }\n    }\n    \n    // Cleanup\n    for (const job of jobs) {\n      await redis.del(''job:'' + job.id);\n      await redis.zrem(''jobs:pending'', job.id);\n    }\n    \n    await redis.quit();\n    console.log(''\\nüéâ Capability filtering test completed!'');\n    \n  } catch (error) {\n    console.error(''‚ùå Capability filtering test failed:'', error.message);\n    process.exit(1);\n  }\n}\n\ntestCapabilityFiltering();\n\")",
      "Bash(REDIS_URL=\"redis://default:JQSoNVpIPsuaDQYicNvocglialxPrTjj@ballast.proxy.rlwy.net:30645\" node -e \"\nconst Redis = require(''ioredis'');\nconst redis = new Redis(process.env.REDIS_URL);\n\nasync function testSortingOrder() {\n  try {\n    console.log(''üîç Testing Redis Function Sorting Priority...'');\n    \n    // Create jobs with different priorities and timestamps\n    const now = Date.now();\n    const jobs = [\n      {\n        id: ''job-high-old'',\n        priority: 100,\n        created_at: new Date(now - 60000).toISOString(), // 1 minute ago\n        score_type: ''High priority, older''\n      },\n      {\n        id: ''job-medium-new'', \n        priority: 50,\n        created_at: new Date(now).toISOString(), // Now\n        score_type: ''Medium priority, newer''\n      },\n      {\n        id: ''job-high-new'',\n        priority: 100, \n        created_at: new Date(now).toISOString(), // Now\n        score_type: ''High priority, newer''\n      },\n      {\n        id: ''job-low-old'',\n        priority: 10,\n        created_at: new Date(now - 120000).toISOString(), // 2 minutes ago  \n        score_type: ''Low priority, oldest''\n      }\n    ];\n    \n    // Submit jobs using the API server scoring method\n    for (const jobInfo of jobs) {\n      const job = {\n        id: jobInfo.id,\n        service_required: ''simulation'',\n        priority: jobInfo.priority.toString(),\n        payload: JSON.stringify({ test: true }),\n        requirements: JSON.stringify({}),\n        created_at: jobInfo.created_at,\n        status: ''pending'',\n        retry_count: ''0'',\n        max_retries: ''3''\n      };\n      \n      await redis.hmset(''job:'' + job.id, job);\n      \n      // Use the API server scoring: priority * 1000 + timestamp  \n      const score = job.priority * 1000 + Date.parse(job.created_at);\n      await redis.zadd(''jobs:pending'', score, job.id);\n      \n      console.log(\\`‚úÖ ${jobInfo.score_type}: score=${score}\\`);\n    }\n    \n    // Check the order Redis returns them\n    console.log(''\\nüìã Redis ZREVRANGE order (highest score first):'');\n    const orderedJobs = await redis.zrevrange(''jobs:pending'', 0, -1, ''WITHSCORES'');\n    \n    for (let i = 0; i < orderedJobs.length; i += 2) {\n      const jobId = orderedJobs[i];\n      const score = orderedJobs[i + 1];\n      const jobData = await redis.hgetall(''job:'' + jobId);\n      console.log(\\`  ${i/2 + 1}. ${jobId} (priority: ${jobData.priority}, score: ${score})\\`);\n    }\n    \n    // Test Redis function selection order\n    console.log(''\\nü§ñ Redis function job selection order:'');\n    const worker = {\n      worker_id: ''test-worker'',\n      services: [''simulation'']\n    };\n    \n    for (let i = 0; i < 4; i++) {\n      const result = await redis.fcall(\n        ''findMatchingJob'',\n        0,\n        JSON.stringify(worker),\n        ''1''  // Only get 1 job at a time\n      );\n      \n      if (result) {\n        const match = JSON.parse(result);\n        const jobData = await redis.hgetall(''job:'' + match.jobId);\n        console.log(\\`  ${i + 1}. Selected: ${match.jobId} (priority: ${jobData.priority})\\`);\n        \n        // Put it back as completed so next iteration gets next job\n        await redis.hmset(''job:'' + match.jobId, ''status'', ''completed'');\n        await redis.zadd(''jobs:pending'', parseInt(jobData.priority) * 1000 + Date.now(), match.jobId);\n      } else {\n        console.log(\\`  ${i + 1}. No more jobs found\\`);\n        break;\n      }\n    }\n    \n    // Cleanup\n    for (const jobInfo of jobs) {\n      await redis.del(''job:'' + jobInfo.id);\n      await redis.zrem(''jobs:pending'', jobInfo.id);\n    }\n    \n    await redis.quit();\n    console.log(''\\nüéâ Sorting test completed!'');\n    \n  } catch (error) {\n    console.error(''‚ùå Sorting test failed:'', error.message);\n    process.exit(1);\n  }\n}\n\ntestSortingOrder();\n\")",
      "Bash(REDIS_URL=\"redis://default:JQSoNVpIPsuaDQYicNvocglialxPrTjj@ballast.proxy.rlwy.net:30645\" node -e \"\nconst Redis = require(''ioredis'');\nconst redis = new Redis(process.env.REDIS_URL);\n\nasync function testWorkflowAwareSorting() {\n  try {\n    console.log(''üîç Testing Workflow-Aware Job Sorting...'');\n    \n    const now = Date.now();\n    const jobs = [\n      {\n        id: ''job-no-workflow-high'',\n        priority: 100,\n        created_at: new Date(now - 60000).toISOString(),\n        description: ''High priority job, no workflow''\n      },\n      {\n        id: ''job-workflow-medium-old'',\n        priority: 50,  // job priority\n        workflow_priority: 200,  // workflow priority (higher!)\n        created_at: new Date(now - 30000).toISOString(),\n        workflow_datetime: now - 120000,  // older workflow\n        description: ''Medium job priority, high workflow priority, older workflow''\n      },\n      {\n        id: ''job-workflow-low-new'',\n        priority: 80,  // job priority  \n        workflow_priority: 150,  // workflow priority\n        created_at: new Date(now).toISOString(),\n        workflow_datetime: now - 30000,  // newer workflow\n        description: ''High job priority, medium workflow priority, newer workflow''\n      },\n      {\n        id: ''job-no-workflow-medium'',\n        priority: 75,\n        created_at: new Date(now).toISOString(),\n        description: ''Medium priority job, no workflow, newest''\n      }\n    ];\n    \n    // Submit jobs using new workflow-aware scoring\n    for (const jobInfo of jobs) {\n      const job = {\n        id: jobInfo.id,\n        service_required: ''simulation'',\n        priority: jobInfo.priority.toString(),\n        workflow_priority: jobInfo.workflow_priority?.toString(),\n        workflow_datetime: jobInfo.workflow_datetime?.toString(),\n        payload: JSON.stringify({ test: true }),\n        requirements: JSON.stringify({}),\n        created_at: jobInfo.created_at,\n        status: ''pending'',\n        retry_count: ''0'',\n        max_retries: ''3''\n      };\n      \n      await redis.hmset(''job:'' + job.id, job);\n      \n      // Use new workflow-aware scoring\n      const effectivePriority = jobInfo.workflow_priority || jobInfo.priority;\n      const effectiveDateTime = jobInfo.workflow_datetime || Date.parse(jobInfo.created_at);\n      const score = effectivePriority * 1000000 + effectiveDateTime;\n      \n      await redis.zadd(''jobs:pending'', score, job.id);\n      console.log(\\`‚úÖ ${jobInfo.description}: score=${score}\\`);\n    }\n    \n    // Check Redis ordering\n    console.log(''\\nüìã Redis ZREVRANGE order (highest score first):'');\n    const orderedJobs = await redis.zrevrange(''jobs:pending'', 0, -1, ''WITHSCORES'');\n    \n    for (let i = 0; i < orderedJobs.length; i += 2) {\n      const jobId = orderedJobs[i];\n      const score = orderedJobs[i + 1];\n      const jobData = await redis.hgetall(''job:'' + jobId);\n      console.log(\\`  ${i/2 + 1}. ${jobId}\\`);\n      console.log(\\`     Priority: ${jobData.priority}, Workflow Priority: ${jobData.workflow_priority || ''none''}\\`);\n      console.log(\\`     Score: ${score}\\`);\n    }\n    \n    // Test Redis function selection order\n    console.log(''\\nü§ñ Redis function job selection order:'');\n    const worker = {\n      worker_id: ''test-workflow-worker'',\n      services: [''simulation'']\n    };\n    \n    const selectedJobs = [];\n    for (let i = 0; i < 4; i++) {\n      const result = await redis.fcall(\n        ''findMatchingJob'',\n        0,\n        JSON.stringify(worker),\n        ''10''\n      );\n      \n      if (result) {\n        const match = JSON.parse(result);\n        const jobData = await redis.hgetall(''job:'' + match.jobId);\n        selectedJobs.push(match.jobId);\n        \n        console.log(\\`  ${i + 1}. Selected: ${match.jobId}\\`);\n        console.log(\\`     Job Priority: ${jobData.priority}\\`);\n        console.log(\\`     Workflow Priority: ${jobData.workflow_priority || ''none''}\\`);\n        \n        // Mark as completed to continue test\n        await redis.hmset(''job:'' + match.jobId, ''status'', ''completed'');\n      } else {\n        console.log(\\`  ${i + 1}. No more jobs found\\`);\n        break;\n      }\n    }\n    \n    console.log(''\\nüéØ Expected order: workflow_priority > job_priority, then workflow_datetime > created_at'');\n    console.log(''üìä Actual selection order:'', selectedJobs);\n    \n    // Cleanup\n    for (const jobInfo of jobs) {\n      await redis.del(''job:'' + jobInfo.id);\n      await redis.zrem(''jobs:pending'', jobInfo.id);\n    }\n    \n    await redis.quit();\n    console.log(''\\nüéâ Workflow-aware sorting test completed!'');\n    \n  } catch (error) {\n    console.error(''‚ùå Workflow-aware sorting test failed:'', error.message);\n    process.exit(1);\n  }\n}\n\ntestWorkflowAwareSorting();\n\")",
      "Bash(REDIS_URL=\"redis://default:JQSoNVpIPsuaDQYicNvocglialxPrTjj@ballast.proxy.rlwy.net:30645\" node -e \"\nconst Redis = require(''ioredis'');\nconst redis = new Redis(process.env.REDIS_URL);\n\nasync function testSamePriorityTimingOrder() {\n  try {\n    console.log(''üîç Testing Same Priority + Timing Order...'');\n    \n    const now = Date.now();\n    const jobs = [\n      {\n        id: ''job-workflow-priority50-newer'',\n        priority: 50,\n        workflow_priority: 50,  // Same effective priority\n        created_at: new Date(now - 30000).toISOString(),      // 30s ago (job time)\n        workflow_datetime: now - 10000,  // 10s ago (workflow time) - NEWER\n        description: ''Workflow job, same priority, NEWER workflow time''\n      },\n      {\n        id: ''job-standalone-priority50-older'', \n        priority: 50,  // Same effective priority\n        // No workflow\n        created_at: new Date(now - 60000).toISOString(),      // 60s ago - OLDER\n        description: ''Standalone job, same priority, OLDER creation time''\n      }\n    ];\n    \n    // Submit jobs using workflow-aware scoring\n    for (const jobInfo of jobs) {\n      const job = {\n        id: jobInfo.id,\n        service_required: ''simulation'',\n        priority: jobInfo.priority.toString(),\n        workflow_priority: jobInfo.workflow_priority?.toString(),\n        workflow_datetime: jobInfo.workflow_datetime?.toString(),\n        payload: JSON.stringify({ test: true }),\n        requirements: JSON.stringify({}),\n        created_at: jobInfo.created_at,\n        status: ''pending'',\n        retry_count: ''0'',\n        max_retries: ''3''\n      };\n      \n      await redis.hmset(''job:'' + job.id, job);\n      \n      // Calculate scores using our formula\n      const effectivePriority = jobInfo.workflow_priority || jobInfo.priority;\n      const effectiveDateTime = jobInfo.workflow_datetime || Date.parse(jobInfo.created_at);\n      const score = effectivePriority * 1000000 + effectiveDateTime;\n      \n      await redis.zadd(''jobs:pending'', score, job.id);\n      console.log(\\`‚úÖ ${jobInfo.description}\\`);\n      console.log(\\`   Effective Priority: ${effectivePriority}\\`);\n      console.log(\\`   Effective DateTime: ${effectiveDateTime} (${new Date(effectiveDateTime).toISOString()})\\`);\n      console.log(\\`   Score: ${score}\\n\\`);\n    }\n    \n    // Check Redis ordering\n    console.log(''üìã Redis ZREVRANGE order (highest score first):'');\n    const orderedJobs = await redis.zrevrange(''jobs:pending'', 0, -1, ''WITHSCORES'');\n    \n    for (let i = 0; i < orderedJobs.length; i += 2) {\n      const jobId = orderedJobs[i];\n      const score = orderedJobs[i + 1];\n      console.log(\\`  ${i/2 + 1}. ${jobId} (score: ${score})\\`);\n    }\n    \n    // Test Redis function selection order\n    console.log(''\\nü§ñ Redis function selection order:'');\n    const worker = { worker_id: ''test-timing-worker'', services: [''simulation''] };\n    \n    for (let i = 0; i < 2; i++) {\n      const result = await redis.fcall(''findMatchingJob'', 0, JSON.stringify(worker), ''10'');\n      \n      if (result) {\n        const match = JSON.parse(result);\n        console.log(\\`  ${i + 1}. Selected: ${match.jobId}\\`);\n        await redis.hmset(''job:'' + match.jobId, ''status'', ''completed'');\n      }\n    }\n    \n    console.log(''\\nüéØ Analysis:'');\n    console.log(''Same priority (50), but different effective datetimes:'');\n    console.log(''- Standalone job: created_at = ${new Date(now - 60000).toISOString()} (older)'');\n    console.log(''- Workflow job: workflow_datetime = ${new Date(now - 10000).toISOString()} (newer)'');\n    console.log('''');\n    console.log(''Expected: Standalone job should be selected FIRST (older datetime wins)'');\n    \n    // Cleanup\n    for (const jobInfo of jobs) {\n      await redis.del(''job:'' + jobInfo.id);\n      await redis.zrem(''jobs:pending'', jobInfo.id);\n    }\n    \n    await redis.quit();\n    console.log(''\\nüéâ Same priority timing test completed!'');\n    \n  } catch (error) {\n    console.error(''‚ùå Same priority timing test failed:'', error.message);\n    process.exit(1);\n  }\n}\n\ntestSamePriorityTimingOrder();\n\")",
      "Bash(REDIS_URL=\"redis://default:JQSoNVpIPsuaDQYicNvocglialxPrTjj@ballast.proxy.rlwy.net:30645\" node -e \"\nconst Redis = require(''ioredis'');\nconst redis = new Redis(process.env.REDIS_URL);\n\nasync function testFIFOBehavior() {\n  try {\n    console.log(''üîç Testing FIFO vs LIFO Behavior...'');\n    \n    const baseTime = 1700000000000; // Fixed base time for clarity\n    const jobs = [\n      {\n        id: ''job-older'',\n        priority: 50,\n        created_at: new Date(baseTime).toISOString(),     // Earlier\n        description: ''Older job (should be processed FIRST in FIFO)''\n      },\n      {\n        id: ''job-newer'',\n        priority: 50, \n        created_at: new Date(baseTime + 60000).toISOString(), // Later\n        description: ''Newer job (should be processed SECOND in FIFO)''\n      }\n    ];\n    \n    for (const jobInfo of jobs) {\n      const effectiveDateTime = Date.parse(jobInfo.created_at);\n      const score = jobInfo.priority * 1000000 + effectiveDateTime;\n      \n      await redis.hmset(''job:'' + jobInfo.id, {\n        id: jobInfo.id,\n        service_required: ''simulation'',\n        priority: jobInfo.priority.toString(),\n        created_at: jobInfo.created_at,\n        status: ''pending''\n      });\n      \n      await redis.zadd(''jobs:pending'', score, jobInfo.id);\n      console.log(\\`‚úÖ ${jobInfo.description}\\`);\n      console.log(\\`   DateTime: ${jobInfo.created_at}\\`);\n      console.log(\\`   Score: ${score}\\n\\`);\n    }\n    \n    // Check ordering\n    const orderedJobs = await redis.zrevrange(''jobs:pending'', 0, -1, ''WITHSCORES'');\n    console.log(''üìã Current Redis order (ZREVRANGE - highest score first):'');\n    \n    for (let i = 0; i < orderedJobs.length; i += 2) {\n      const jobId = orderedJobs[i];\n      const score = orderedJobs[i + 1];\n      console.log(\\`  ${i/2 + 1}. ${jobId} (score: ${score})\\`);\n    }\n    \n    console.log(''\\nüéØ Analysis:'');\n    console.log(''Current: NEWER job has HIGHER score ‚Üí selected FIRST (LIFO)'');\n    console.log(''Desired: OLDER job should have HIGHER score ‚Üí selected FIRST (FIFO)'');\n    console.log(''\\nüí° Solution: Use NEGATIVE timestamp in score calculation'');\n    console.log(''   score = priority * 1000000 + (MAX_TIMESTAMP - effectiveDateTime)'');\n    console.log(''   This makes older jobs have higher scores = FIFO behavior'');\n    \n    // Cleanup\n    for (const jobInfo of jobs) {\n      await redis.del(''job:'' + jobInfo.id);\n      await redis.zrem(''jobs:pending'', jobInfo.id);\n    }\n    \n    await redis.quit();\n    console.log(''\\nüéâ FIFO behavior test completed!'');\n    \n  } catch (error) {\n    console.error(''‚ùå FIFO behavior test failed:'', error.message);\n    process.exit(1);\n  }\n}\n\ntestFIFOBehavior();\n\")",
      "Bash(REDIS_URL=\"redis://default:JQSoNVpIPsuaDQYicNvocglialxPrTjj@ballast.proxy.rlwy.net:30645\" node -e \"\nconst Redis = require(''ioredis'');\nconst redis = new Redis(process.env.REDIS_URL);\n\nasync function testCorrectedFIFO() {\n  try {\n    console.log(''üîç Testing CORRECTED FIFO Behavior...'');\n    \n    const baseTime = 1700000000000;\n    const jobs = [\n      {\n        id: ''job-older-standalone'',\n        priority: 50,\n        created_at: new Date(baseTime).toISOString(),\n        description: ''Older standalone job (should be FIRST)''\n      },\n      {\n        id: ''job-newer-workflow'',\n        priority: 50,\n        workflow_priority: 50,  // Same effective priority\n        created_at: new Date(baseTime + 30000).toISOString(),\n        workflow_datetime: baseTime + 60000,  // Even newer workflow time\n        description: ''Newer workflow job (should be SECOND)''\n      }\n    ];\n    \n    for (const jobInfo of jobs) {\n      const effectivePriority = jobInfo.workflow_priority || jobInfo.priority;\n      const effectiveDateTime = jobInfo.workflow_datetime || Date.parse(jobInfo.created_at);\n      // NEW CORRECTED FORMULA\n      const score = effectivePriority * 1000000 + (Number.MAX_SAFE_INTEGER - effectiveDateTime);\n      \n      await redis.hmset(''job:'' + jobInfo.id, {\n        id: jobInfo.id,\n        service_required: ''simulation'',\n        priority: jobInfo.priority.toString(),\n        workflow_priority: jobInfo.workflow_priority?.toString(),\n        workflow_datetime: jobInfo.workflow_datetime?.toString(),\n        created_at: jobInfo.created_at,\n        status: ''pending''\n      });\n      \n      await redis.zadd(''jobs:pending'', score, jobInfo.id);\n      console.log(\\`‚úÖ ${jobInfo.description}\\`);\n      console.log(\\`   Effective DateTime: ${new Date(effectiveDateTime).toISOString()}\\`);\n      console.log(\\`   Score: ${score}\\n\\`);\n    }\n    \n    // Check Redis ordering\n    const orderedJobs = await redis.zrevrange(''jobs:pending'', 0, -1, ''WITHSCORES'');\n    console.log(''üìã Redis order (ZREVRANGE - highest score first):'');\n    \n    for (let i = 0; i < orderedJobs.length; i += 2) {\n      const jobId = orderedJobs[i];\n      const score = orderedJobs[i + 1];\n      console.log(\\`  ${i/2 + 1}. ${jobId} (score: ${score})\\`);\n    }\n    \n    // Test function selection\n    console.log(''\\nü§ñ Redis function selection order:'');\n    const worker = { worker_id: ''test-fifo-worker'', services: [''simulation''] };\n    \n    for (let i = 0; i < 2; i++) {\n      const result = await redis.fcall(''findMatchingJob'', 0, JSON.stringify(worker), ''10'');\n      \n      if (result) {\n        const match = JSON.parse(result);\n        console.log(\\`  ${i + 1}. Selected: ${match.jobId}\\`);\n        await redis.hmset(''job:'' + match.jobId, ''status'', ''completed'');\n      }\n    }\n    \n    console.log(''\\nüéØ Expected: Older job selected first = TRUE FIFO!'');\n    \n    // Cleanup\n    for (const jobInfo of jobs) {\n      await redis.del(''job:'' + jobInfo.id);\n      await redis.zrem(''jobs:pending'', jobInfo.id);\n    }\n    \n    await redis.quit();\n    console.log(''\\nüéâ Corrected FIFO test completed!'');\n    \n  } catch (error) {\n    console.error(''‚ùå Corrected FIFO test failed:'', error.message);\n    process.exit(1);\n  }\n}\n\ntestCorrectedFIFO();\n\")",
      "Bash(git add:*)",
      "Bash(pnpm add:*)",
      "Bash(git reset:*)",
      "Bash(rm:*)",
      "Bash(node:*)",
      "Bash(cp:*)",
      "Bash(npx eslint:*)",
      "Bash(pnpm redis-functions:install:*)",
      "Bash(REDIS_URL=redis://default:JQSoNVpIPsuaDQYicNvocglialxPrTjj@ballast.proxy.rlwy.net:30645 pnpm redis:functions:install)",
      "Bash(docker-compose:*)",
      "Bash(npx tsc:*)",
      "Bash(npx next lint:*)",
      "Bash(pnpm redis:functions:test:*)",
      "Bash(pnpm docker:capability-test:build:*)",
      "Bash(tar:*)",
      "Bash(git --git-dir=/Users/the_dusky/code/emprops/ai_infra/emp-worker-old/.git branch)",
      "Bash(npx turbo gen:*)",
      "Bash(git mv:*)",
      "Bash(turbo:*)",
      "Bash(npx turbo:*)",
      "Bash(pnpm list:*)",
      "Bash(pnpm type-check:*)",
      "Bash(pnpm docker:down:*)",
      "Bash(pnpm --filter=@emp/core build)",
      "Bash(docker run:*)",
      "Bash(pnpm railway:start:*)",
      "Bash(pnpm start:*)",
      "Bash(pnpm railway:build:*)",
      "Bash(docker build:*)",
      "Bash(git push:*)",
      "Bash(git tag:*)",
      "Bash(git ls-tree:*)",
      "Bash(sed:*)",
      "Bash(pnpm machines:basic:up:*)",
      "WebFetch(domain:github.com)",
      "Bash(pnpm setup:*)",
      "Bash(npm install:*)",
      "Bash(pnpm --filter @emp/core build)",
      "Bash(pnpm --filter worker build)",
      "Bash(esbuild:*)",
      "Bash(--bundle )",
      "Bash(--platform=node )",
      "Bash(--target=node18 )",
      "Bash(--format=esm )",
      "Bash(--external:sharp )",
      "Bash(--external:canvas )",
      "Bash(--external:@tensorflow/tfjs-node )",
      "Bash(--external:sqlite3 )",
      "Bash(--banner:js=\"#!/usr/bin/env node\" )",
      "Bash(--outfile=test-worker-release/redis-direct-worker.js)",
      "Bash(HUB_REDIS_URL=redis://test:test@localhost:6379 WORKER_ID=test-worker node redis-direct-worker.js --help)",
      "Bash(--bundle )",
      "Bash(--platform=node )",
      "Bash(--target=node18 )",
      "Bash(--format=esm )",
      "Bash(--external:sharp )",
      "Bash(--external:canvas )",
      "Bash(--external:@tensorflow/tfjs-node )",
      "Bash(--external:sqlite3 )",
      "Bash(timeout:*)",
      "Bash(--bundle )",
      "Bash(--platform=node )",
      "Bash(--target=node18 )",
      "Bash(--format=cjs )",
      "Bash(--external:sharp )",
      "Bash(--external:canvas )",
      "Bash(--external:@tensorflow/tfjs-node )",
      "Bash(--external:sqlite3 )",
      "Bash(--bundle )",
      "Bash(--platform=node )",
      "Bash(--target=node18 )",
      "Bash(--format=cjs )",
      "Bash(--external:sharp )",
      "Bash(--external:canvas )",
      "Bash(--external:@tensorflow/tfjs-node )",
      "Bash(--external:sqlite3 )",
      "Bash(--outfile=test-worker-release/redis-direct-worker.cjs)",
      "Bash(git rm:*)",
      "Bash(true)",
      "Bash(npm run build:*)",
      "Bash(npm run:*)",
      "Bash(HUB_REDIS_URL=redis://localhost:6379 TEST_MODE=true NUM_GPUS=1 ENABLE_NGINX=false ENABLE_A1111=false ENABLE_OLLAMA=false node -e \"\nimport(''./src/config/environment.js'').then(config => {\n  console.log(''Configuration loaded successfully:'');\n  console.log(''GPU Count:'', config.default.machine.gpu.count);\n  console.log(''Test Mode:'', config.default.machine.testMode);\n  console.log(''Services enabled:'', Object.entries(config.default.services).filter(([_,s]) => s.enabled).map(([name]) => name));\n  console.log(''ComfyUI base port:'', config.default.services.comfyui.basePort);\n}).catch(console.error);\n\")",
      "Bash(HUB_REDIS_URL=redis://localhost:6379 TEST_MODE=true NUM_GPUS=1 ENABLE_NGINX=false ENABLE_A1111=false ENABLE_OLLAMA=false node test-comfyui.js)",
      "Bash(WORKSPACE_DIR=/tmp/workspace HUB_REDIS_URL=redis://localhost:6379 TEST_MODE=true NUM_GPUS=1 ENABLE_NGINX=false ENABLE_A1111=false ENABLE_OLLAMA=false node test-comfyui.js)",
      "Bash(WORKSPACE_DIR=/tmp/workspace HUB_REDIS_URL=redis://localhost:6379 TEST_MODE=true NUM_GPUS=1 ENABLE_NGINX=false ENABLE_A1111=false ENABLE_OLLAMA=false node test-comfyui-start.js)",
      "Bash(WORKSPACE_DIR=/tmp/workspace HUB_REDIS_URL=redis://localhost:6379 TEST_MODE=true NUM_GPUS=1 ENABLE_NGINX=false ENABLE_A1111=false ENABLE_OLLAMA=false COMFYUI_BASE_PORT=8200 node test-comfyui-start.js)",
      "Bash(cat:*)",
      "Bash(WORKSPACE_DIR=/tmp/workspace HUB_REDIS_URL=redis://localhost:6379 TEST_MODE=true NUM_GPUS=1 ENABLE_NGINX=false ENABLE_A1111=false ENABLE_OLLAMA=false COMFYUI_BASE_PORT=8200 LOG_LEVEL=debug node test-comfyui-start.js)",
      "Bash(WORKSPACE_DIR=/tmp/workspace LOG_LEVEL=debug node test-comfyui-simple.js)",
      "Bash(WORKSPACE_DIR=/tmp/workspace LOG_LEVEL=info node test-comfyui-simple.js)",
      "Bash(awk:*)",
      "Bash(pnpm --filter=api build)"
    ],
    "deny": []
  }
}