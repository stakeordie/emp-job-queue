#!/bin/bash

# w2gpu - Worker v2 GPU management script
# Uses the new TypeScript worker from apps/worker instead of Python worker
# Parallel implementation to wgpu for safe migration

# Base directory for Redis Worker instances
ROOT="${ROOT:-/workspace}"
LOG_DIR="${ROOT}/logs"
START_LOG="${LOG_DIR}/start.log"

# Default values from environment
NUM_GPUS="${NUM_GPUS:-1}"

# Ensure log directory exists
mkdir -p "$LOG_DIR"
chmod 755 "$LOG_DIR"
touch "$START_LOG"
chmod 644 "$START_LOG"

# Logging function
log() {
    local timestamp=$(date '+%Y-%m-%d %H:%M:%S')
    local msg="[w2gpu] $*"
    local log_line="[$timestamp] $msg"
    
    echo "$log_line"
    echo "$log_line" >> "$START_LOG"
}

# Load environment variables from env.sh
load_environment_variables() {
    local log_prefix="$1"
    
    if [ -f "/etc/profile.d/env.sh" ]; then
        log "[$log_prefix] Loading environment variables from /etc/profile.d/env.sh"
        source "/etc/profile.d/env.sh"
    else
        log "[$log_prefix] WARNING: Environment file /etc/profile.d/env.sh not found"
        
        # Fallback to /etc/environment if env.sh doesn't exist
        if [ -f /etc/environment ]; then
            log "[$log_prefix] Falling back to /etc/environment"
            while IFS='=' read -r key value; do
                if [ -n "$key" ]; then
                    # Remove any leading/trailing whitespace and quotes
                    key=$(echo "$key" | tr -d '"' | xargs)
                    value=$(echo "$value" | tr -d '"' | xargs)
                    export "$key"="$value"
                fi
            done < /etc/environment
        fi
    fi
}

# Validate GPU ID
validate_gpu_id() {
    local gpu_id=$1
    
    if ! [[ "$gpu_id" =~ ^[0-9]+$ ]]; then
        log "Invalid GPU ID: $gpu_id (must be a number)"
        return 1
    fi
    
    if [ "$gpu_id" -ge "$NUM_GPUS" ]; then
        log "GPU ID $gpu_id is out of range (0-$((NUM_GPUS-1)))"
        return 1
    fi
    
    return 0
}

# Setup GPU worker directory and configuration
setup_gpu() {
    local gpu_id=$1
    
    validate_gpu_id "$gpu_id" || return 1
    
    local work_dir="${ROOT}/worker_gpu${gpu_id}"
    local logs_dir="${work_dir}/logs"
    
    log "Setting up GPU $gpu_id worker directory at $work_dir"
    
    # Create directories
    mkdir -p "$work_dir"
    mkdir -p "$logs_dir"
    chmod 755 "$work_dir"
    chmod 755 "$logs_dir"
    
    # Create log files
    touch "${logs_dir}/output.log"
    touch "${logs_dir}/error.log"
    chmod 644 "${logs_dir}/output.log"
    chmod 644 "${logs_dir}/error.log"
    
    # Create basic .env file for this worker
    cat > "${work_dir}/.env" << EOF
# Worker v2 Configuration for GPU $gpu_id
WORKER_ID=worker-gpu${gpu_id}
WORKER_MACHINE_GPU_COUNT=${NUM_GPUS}
WORKER_GPU_ID=${gpu_id}
WORKER_SERVICES=comfyui,simulation
WORKER_CONNECTORS=comfyui,simulation
WORKER_POLL_INTERVAL_MS=1000
WORKER_HEARTBEAT_INTERVAL_MS=30000
WORKER_JOB_TIMEOUT_MINUTES=30

# ComfyUI Configuration
WORKER_COMFYUI_HOST=localhost
WORKER_COMFYUI_PORT=3188
WORKER_COMFYUI_USE_BASIC_AUTH=false

# Simulation Configuration
WORKER_SIMULATION_PROCESSING_TIME=5
WORKER_SIMULATION_STEPS=10

# Hardware specs (basic defaults - can be customized)
WORKER_GPU_MEMORY_GB=8
WORKER_GPU_MODEL=Development
WORKER_MACHINE_ID=base-machine

# Redis connection (will be set by container)
HUB_REDIS_URL=\${HUB_REDIS_URL:-redis://localhost:6379}

# Logging
LOG_LEVEL=info
DISABLE_FILE_LOGGING=false
EOF
    
    log "Created worker configuration at ${work_dir}/.env"
    log "GPU $gpu_id setup complete"
}

# Setup all GPUs
setup_all_gpus() {
    if [ "$NUM_GPUS" -eq 0 ]; then
        log "No GPUs configured. Check NUM_GPUS environment variable."
        return 1
    fi
    
    log "Setting up all GPUs (0-$((NUM_GPUS-1)))"
    
    for ((gpu=0; gpu<NUM_GPUS; gpu++)); do
        setup_gpu "$gpu"
    done
}

# Start worker for specific GPU
start_service() {
    local gpu_id=$1
    
    validate_gpu_id "$gpu_id" || return 1
    
    local work_dir="${ROOT}/worker_gpu${gpu_id}"
    local pid_file="${work_dir}/worker.pid"
    local log_file="${work_dir}/logs/output.log"
    local error_file="${work_dir}/logs/error.log"
    
    # Check if already running
    if [ -f "$pid_file" ] && kill -0 "$(cat "$pid_file")" 2>/dev/null; then
        log "Worker for GPU $gpu_id is already running (PID: $(cat "$pid_file"))"
        return 0
    fi
    
    # Ensure directory exists
    if [ ! -d "$work_dir" ]; then
        log "ERROR: Working directory $work_dir does not exist"
        log "Run 'w2gpu setup $gpu_id' to create it"
        return 1
    fi
    
    log "Starting TypeScript worker for GPU $gpu_id"
    
    # Load environment variables
    load_environment_variables "GPU$gpu_id"
    
    # Load worker-specific environment
    if [ -f "${work_dir}/.env" ]; then
        log "Loading worker configuration from ${work_dir}/.env"
        set -a
        source "${work_dir}/.env"
        set +a
    fi
    
    # Find the worker binary - look for our built TypeScript worker
    local worker_cmd=""
    
    # Check for worker in various locations
    if [ -f "/workspace/emp-job-queue/apps/worker/dist/redis-direct-worker.js" ]; then
        worker_cmd="node /workspace/emp-job-queue/apps/worker/dist/redis-direct-worker.js"
    elif [ -f "/workspace/apps/worker/dist/redis-direct-worker.js" ]; then
        worker_cmd="node /workspace/apps/worker/dist/redis-direct-worker.js"
    elif [ -f "${work_dir}/worker/dist/redis-direct-worker.js" ]; then
        worker_cmd="node ${work_dir}/worker/dist/redis-direct-worker.js"
    else
        log "ERROR: TypeScript worker binary not found"
        log "Expected locations:"
        log "  - /workspace/emp-job-queue/apps/worker/dist/redis-direct-worker.js"
        log "  - /workspace/apps/worker/dist/redis-direct-worker.js"
        log "  - ${work_dir}/worker/dist/redis-direct-worker.js"
        return 1
    fi
    
    log "Using worker command: $worker_cmd"
    
    # Start the worker in background
    cd "$work_dir" || {
        log "ERROR: Cannot change to worker directory $work_dir"
        return 1
    }
    
    # Start with nohup and redirect output
    nohup $worker_cmd > "$log_file" 2> "$error_file" &
    local worker_pid=$!
    
    # Save PID
    echo $worker_pid > "$pid_file"
    
    # Wait a moment and check if it's still running
    sleep 2
    if kill -0 $worker_pid 2>/dev/null; then
        log "Worker for GPU $gpu_id started successfully (PID: $worker_pid)"
        return 0
    else
        log "ERROR: Worker for GPU $gpu_id failed to start"
        return 1
    fi
}

# Stop worker for specific GPU
stop_service() {
    local gpu_id=$1
    
    validate_gpu_id "$gpu_id" || return 1
    
    local work_dir="${ROOT}/worker_gpu${gpu_id}"
    local pid_file="${work_dir}/worker.pid"
    
    if [ ! -f "$pid_file" ]; then
        log "Worker for GPU $gpu_id is not running (no PID file)"
        return 0
    fi
    
    local pid=$(cat "$pid_file")
    
    if ! kill -0 "$pid" 2>/dev/null; then
        log "Worker for GPU $gpu_id is not running (stale PID file)"
        rm -f "$pid_file"
        return 0
    fi
    
    log "Stopping worker for GPU $gpu_id (PID: $pid)"
    
    # Try graceful shutdown first
    kill "$pid"
    
    # Wait up to 10 seconds for graceful shutdown
    for i in {1..10}; do
        if ! kill -0 "$pid" 2>/dev/null; then
            break
        fi
        sleep 1
    done
    
    # Force kill if still running
    if kill -0 "$pid" 2>/dev/null; then
        log "Force killing worker for GPU $gpu_id"
        kill -9 "$pid"
    fi
    
    rm -f "$pid_file"
    log "Worker for GPU $gpu_id stopped"
}

# Check status of worker for specific GPU
check_status() {
    local gpu_id=$1
    
    validate_gpu_id "$gpu_id" || return 1
    
    local work_dir="${ROOT}/worker_gpu${gpu_id}"
    local pid_file="${work_dir}/worker.pid"
    
    if [ ! -f "$pid_file" ]; then
        log "Worker for GPU $gpu_id: NOT RUNNING (no PID file)"
        return 1
    fi
    
    local pid=$(cat "$pid_file")
    
    if kill -0 "$pid" 2>/dev/null; then
        log "Worker for GPU $gpu_id: RUNNING (PID: $pid)"
        return 0
    else
        log "Worker for GPU $gpu_id: NOT RUNNING (stale PID file)"
        rm -f "$pid_file"
        return 1
    fi
}

# Show logs for specific GPU
show_logs() {
    local gpu_id=$1
    local lines=${2:-100}
    local follow=${3:-1}
    
    validate_gpu_id "$gpu_id" || return 1
    
    local log_file="${ROOT}/worker_gpu${gpu_id}/logs/output.log"
    
    if [ ! -f "$log_file" ]; then
        log "No log file found for GPU $gpu_id at $log_file"
        return 1
    fi
    
    if [ "$follow" -eq 1 ]; then
        log "Tailing logs for worker on GPU $gpu_id (${log_file}) with -f"
        tail -n "$lines" -f "$log_file"
    else
        log "Showing logs for worker on GPU $gpu_id (${log_file})"
        tail -n "$lines" "$log_file"
    fi
}

# Operations for all GPUs
start_all_services() {
    if [ "$NUM_GPUS" -eq 0 ]; then
        log "No GPUs configured. Check NUM_GPUS environment variable."
        return 1
    fi
    
    log "Starting TypeScript workers for all GPUs (0-$((NUM_GPUS-1)))"
    
    for ((gpu=0; gpu<NUM_GPUS; gpu++)); do
        start_service "$gpu"
    done
}

stop_all_services() {
    if [ "$NUM_GPUS" -eq 0 ]; then
        log "No GPUs configured. Check NUM_GPUS environment variable."
        return 1
    fi
    
    log "Stopping TypeScript workers for all GPUs (0-$((NUM_GPUS-1)))"
    
    for ((gpu=0; gpu<NUM_GPUS; gpu++)); do
        stop_service "$gpu"
    done
}

check_all_status() {
    if [ "$NUM_GPUS" -eq 0 ]; then
        log "No GPUs configured. Check NUM_GPUS environment variable."
        return 1
    fi
    
    log "Checking status for all GPUs (0-$((NUM_GPUS-1)))"
    
    for ((gpu=0; gpu<NUM_GPUS; gpu++)); do
        check_status "$gpu"
    done
}

show_all_logs() {
    local lines=${1:-20}
    local follow=${2:-1}
    
    if [ "$NUM_GPUS" -eq 0 ]; then
        log "No GPUs configured. Check NUM_GPUS environment variable."
        return 1
    fi
    
    if [ "$follow" -eq 1 ]; then
        log "Cannot follow logs for multiple GPUs simultaneously. Please specify a single GPU."
        return 1
    fi
    
    for ((gpu=0; gpu<NUM_GPUS; gpu++)); do
        echo "=== GPU $gpu logs ==="
        show_logs "$gpu" "$lines" 0
        echo ""
    done
}

show_count() {
    echo "Configured GPUs: $NUM_GPUS"
    echo "GPU range: 0-$((NUM_GPUS-1))"
}

show_usage() {
    cat << 'EOF'
w2gpu - Worker v2 GPU management script (TypeScript worker)

Usage: w2gpu <command> [arguments]

Commands:
  start <gpu_id|all>     Start worker for specific GPU or all GPUs
  stop <gpu_id|all>      Stop worker for specific GPU or all GPUs  
  restart <gpu_id|all>   Restart worker for specific GPU or all GPUs
  status <gpu_id|all>    Check status of specific GPU or all GPUs
  logs <gpu_id|all> [lines] [--no-follow]    Show logs (default: follow mode)
  setup <gpu_id|all>     Setup worker directory for GPU(s)
  count                  Show number of configured GPUs

Examples:
  w2gpu start 0          Start worker for GPU 0
  w2gpu start all        Start workers for all GPUs
  w2gpu stop 1           Stop worker for GPU 1
  w2gpu status all       Check status of all workers
  w2gpu logs 0           Follow logs for GPU 0
  w2gpu logs all 50 --no-follow    Show last 50 lines for all GPUs
  w2gpu setup all        Setup directories for all GPUs

Environment Variables:
  NUM_GPUS               Number of GPUs (default: 1)
  ROOT                   Base directory (default: /workspace)
  HUB_REDIS_URL         Redis connection string
EOF
}

# Parse arguments
if [ $# -eq 0 ]; then
    show_usage
    exit 1
fi

load_environment_variables "MAIN"

case "$1" in
    start)
        if [ -z "$2" ]; then
            show_usage
            exit 1
        elif [ "$2" = "all" ]; then
            start_all_services
        else
            start_service "$2"
        fi
        ;;
    stop)
        if [ -z "$2" ]; then
            show_usage
            exit 1
        elif [ "$2" = "all" ]; then
            stop_all_services
        else
            stop_service "$2"
        fi
        ;;
    restart)
        if [ -z "$2" ]; then
            show_usage
            exit 1
        elif [ "$2" = "all" ]; then
            stop_all_services
            sleep 2
            start_all_services
        else
            stop_service "$2"
            sleep 2
            start_service "$2"
        fi
        ;;
    status)
        if [ -z "$2" ]; then
            show_usage
            exit 1
        elif [ "$2" = "all" ]; then
            check_all_status
        else
            check_status "$2"
        fi
        ;;
    logs)
        # Parse flags for logs command
        local FOLLOW="1"  # Default to follow mode
        local ARGS=() # Store non-flag arguments
        
        # Skip the first argument (which is "logs")
        shift
        
        # Process remaining arguments
        while [ $# -gt 0 ]; do
            case "$1" in
                --no-follow)
                    FOLLOW="0"
                    shift
                    ;;
                -f|--follow)
                    FOLLOW="1"
                    shift
                    ;;
                *)
                    ARGS+=("$1")
                    shift
                    ;;
            esac
        done
        
        # Check if we have enough arguments
        if [ ${#ARGS[@]} -eq 0 ]; then
            show_usage
            exit 1
        elif [ "${ARGS[0]}" = "all" ]; then
            show_all_logs "${ARGS[1]:-20}" "$FOLLOW"
        else
            show_logs "${ARGS[0]}" "${ARGS[1]:-100}" "$FOLLOW"
        fi
        ;;
    setup)
        if [ -z "$2" ]; then
            show_usage
            exit 1
        elif [ "$2" = "all" ]; then
            setup_all_gpus
        else
            setup_gpu "$2"
        fi
        ;;
    count)
        show_count
        ;;
    *)
        show_usage
        exit 1
        ;;
esac

exit 0