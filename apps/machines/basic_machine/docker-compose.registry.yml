# Production-style Docker Compose that pulls from registry
# This mimics how remote GPU servers would deploy

services:
  basic-machine-registry:
    # Pull from registry instead of building locally
    # NOTE: Currently no machine image published to registry
    # Using local build to simulate registry deployment behavior
    # image: ${DOCKER_IMAGE_NAME}:${DOCKER_IMAGE_TAG}
    
    # Temporary: Local build that mimics registry deployment
    build:
      context: .
      dockerfile: Dockerfile
    
    container_name: ${CONTAINER_NAME}
    hostname: ${CONTAINER_NAME}
    
    # GPU access
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: ${NUM_GPUS}
              capabilities: [gpu]
    
    # Port mapping
    ports:
      - "2225:22"     # SSH
      - "8083:80"     # HTTP
      - "3192:8188"   # ComfyUI GPU0
      - "3193:8189"   # ComfyUI GPU1  
      - "9093:9090"   # Health check
    
    # Environment variables
    environment:
      - TEST_MODE=${TEST_MODE}
      - NUM_GPUS=${NUM_GPUS}
      - GPU_MEMORY_GB=${GPU_MEMORY_GB}
      - GPU_MODEL=${GPU_MODEL}
      - CONTAINER_NAME=${CONTAINER_NAME}
      - MACHINE_ID=${CONTAINER_NAME}
      - HUB_REDIS_URL=${HUB_REDIS_URL}
      - WORKER_CONNECTORS=${WORKER_CONNECTORS}
      - WORKER_WEBSOCKET_AUTH_TOKEN=${WORKER_WEBSOCKET_AUTH_TOKEN}
      - WORKER_ID_PREFIX=${WORKER_ID_PREFIX}
      
      # Remote ComfyUI configuration
      - WORKER_COMFYUI_HOST=${WORKER_COMFYUI_HOST}
      - WORKER_COMFYUI_PORT=${WORKER_COMFYUI_PORT}
      - WORKER_COMFYUI_USERNAME=${WORKER_COMFYUI_USERNAME}
      - WORKER_COMFYUI_PASSWORD=${WORKER_COMFYUI_PASSWORD}
      - WORKER_COMFYUI_TIMEOUT_SECONDS=${WORKER_COMFYUI_TIMEOUT_SECONDS}
      - WORKER_COMFYUI_MAX_CONCURRENT_JOBS=${WORKER_COMFYUI_MAX_CONCURRENT_JOBS}
      
      - ENABLE_NGINX=${ENABLE_NGINX}
      - ENABLE_COMFYUI=${ENABLE_COMFYUI}
      - ENABLE_A1111=${ENABLE_A1111}
      - ENABLE_REDIS_WORKERS=${ENABLE_REDIS_WORKERS}
      - ENABLE_OLLAMA=${ENABLE_OLLAMA}
      - LOG_LEVEL=${LOG_LEVEL}
      - SSH_PORT=${SSH_PORT}
      - NGINX_HTTP_PORT=${NGINX_HTTP_PORT}
      - NGINX_HTTPS_PORT=${NGINX_HTTPS_PORT}
      - COMFYUI_PORT_START=${COMFYUI_PORT_START}
      - COMFYUI_PORT_END=${COMFYUI_PORT_END}
      - A1111_PORT_START=${A1111_PORT_START}
      - A1111_PORT_END=${A1111_PORT_END}
      - OLLAMA_PORT=${OLLAMA_PORT}
      - HEALTH_PORT=${HEALTH_PORT}
      - REDIS_PORT=${REDIS_PORT}
      - SKIP_MODEL_DOWNLOAD=${SKIP_MODEL_DOWNLOAD}
      - HF_TOKEN=${HF_TOKEN}
      - CIVITAI_TOKEN=${CIVITAI_TOKEN}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - AWS_DEFAULT_REGION=${AWS_DEFAULT_REGION}
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY_ENCODED=${AWS_SECRET_ACCESS_KEY_ENCODED}
      - GOOGLE_APPLICATION_CREDENTIALS=${GOOGLE_APPLICATION_CREDENTIALS}
      - AZURE_STORAGE_ACCOUNT=${AZURE_STORAGE_ACCOUNT}
      - AZURE_STORAGE_KEY=${AZURE_STORAGE_KEY}
      - CLOUD_MODELS_CONTAINER=${CLOUD_MODELS_CONTAINER}
      - CLOUD_STORAGE_CONTAINER=${CLOUD_STORAGE_CONTAINER}
      - CLOUD_STORAGE_TEST_CONTAINER=${CLOUD_STORAGE_TEST_CONTAINER}
      - CLOUD_PROVIDER=${CLOUD_PROVIDER}
      - OLLAMA_HOST=${OLLAMA_HOST}
      - OLLAMA_DEFAULT_MODEL=${OLLAMA_DEFAULT_MODEL}
    
    # Volumes for persistent data
    volumes:
      - ./data:/workspace/data
      - ./data/logs:/workspace/logs
      - ./data/models:/workspace/models
      - ./data/ComfyUI:/workspace/ComfyUI
      - ./data/shared:/workspace/shared
      - ./data/stable-diffusion-webui:/workspace/stable-diffusion-webui
    
    # Restart policy
    restart: unless-stopped
    
    # Health check
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9090/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s