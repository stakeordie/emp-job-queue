# Production-Test Docker Compose
# Local machine with production Redis and GitHub worker download
# This mimics production deployment for testing

services:
  basic-machine-prod-test:
    build:
      context: .
      dockerfile: Dockerfile
      args:
        CACHE_BUST: ${CACHE_BUST:-1}
        CUSTOM_NODES_CACHE_BUST: ${CUSTOM_NODES_CACHE_BUST:-default}
        # No sensitive environment variables at build time - all handled at runtime
    
    image: basic-machine-prod-test:latest
    platform: linux/amd64
    container_name: ${CONTAINER_NAME:-basic-machine-prod-test}
    hostname: ${CONTAINER_NAME:-basic-machine-prod-test}
    restart: "no"  # Controlled restart for testing
    
    # Fast shutdown for testing
    stop_grace_period: 2s
    stop_signal: SIGTERM
    
    # GPU support disabled for local testing
    # Running in CPU mode with --cpu flag
    
    # Environment loaded from .env.local.prod-test
    environment:
      - NODE_ENV=production
      - TEST_MODE=${TEST_MODE:-false}
      - NUM_GPUS=${NUM_GPUS:-1}
      - GPU_MEMORY_GB=${GPU_MEMORY_GB:-24}
      - GPU_MODEL=${GPU_MODEL}
      - CONTAINER_NAME=${CONTAINER_NAME}
      - MACHINE_ID=${MACHINE_ID}
      
      # Production Redis connection
      - HUB_REDIS_URL=${HUB_REDIS_URL}
      
      # Worker configuration (downloads from GitHub releases)
      - WORKER_CONNECTORS=${WORKER_CONNECTORS}
      - WORKER_WEBSOCKET_AUTH_TOKEN=${WORKER_WEBSOCKET_AUTH_TOKEN}
      - WORKER_ID_PREFIX=${WORKER_ID_PREFIX}
      
      # Remote ComfyUI configuration
      - WORKER_COMFYUI_HOST=${WORKER_COMFYUI_HOST}
      - WORKER_COMFYUI_PORT=${WORKER_COMFYUI_PORT}
      - WORKER_COMFYUI_USERNAME=${WORKER_COMFYUI_USERNAME}
      - WORKER_COMFYUI_PASSWORD=${WORKER_COMFYUI_PASSWORD}
      - WORKER_COMFYUI_TIMEOUT_SECONDS=${WORKER_COMFYUI_TIMEOUT_SECONDS}
      - WORKER_COMFYUI_MAX_CONCURRENT_JOBS=${WORKER_COMFYUI_MAX_CONCURRENT_JOBS}
      
      # Service toggles
      - ENABLE_NGINX=${ENABLE_NGINX:-false}
      - ENABLE_COMFYUI=${ENABLE_COMFYUI:-true}
      - ENABLE_A1111=${ENABLE_A1111:-false}
      - ENABLE_REDIS_WORKERS=${ENABLE_REDIS_WORKERS:-true}
      - ENABLE_OLLAMA=${ENABLE_OLLAMA:-false}
      - ENABLE_SIMULATION=${ENABLE_SIMULATION:-true}
      
      # ComfyUI CPU mode for local testing
      - COMFYUI_CPU_MODE=${COMFYUI_CPU_MODE:-true}
      
      # Logging
      - LOG_LEVEL=${LOG_LEVEL:-info}
      - EMPROPS_DEBUG_LOGGING=${EMPROPS_DEBUG_LOGGING:-false}
      
      # Ports (internal)
      - SSH_PORT=${SSH_PORT:-22}
      - NGINX_HTTP_PORT=${NGINX_HTTP_PORT:-80}
      - NGINX_HTTPS_PORT=${NGINX_HTTPS_PORT:-443}
      - COMFYUI_PORT_START=${COMFYUI_PORT_START:-8188}
      - COMFYUI_PORT_END=${COMFYUI_PORT_END:-8190}
      - A1111_PORT_START=${A1111_PORT_START:-7860}
      - A1111_PORT_END=${A1111_PORT_END:-7862}
      - OLLAMA_PORT=${OLLAMA_PORT:-11434}
      - HEALTH_PORT=${HEALTH_PORT:-9090}
      - REDIS_PORT=${REDIS_PORT:-6379}
      
      # Model management
      - SKIP_MODEL_DOWNLOAD=${SKIP_MODEL_DOWNLOAD:-false}
      
      # === Runtime Secrets (mimicking platform-provided env vars) ===
      # These would be provided by SALAD/vast.ai in production
      
      # API Tokens
      - HF_TOKEN=${HF_TOKEN}
      - CIVITAI_TOKEN=${CIVITAI_TOKEN}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      
      # Cloud Storage Secrets
      - AWS_DEFAULT_REGION=${AWS_DEFAULT_REGION}
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY_ENCODED=${AWS_SECRET_ACCESS_KEY_ENCODED}
      - GOOGLE_APPLICATION_CREDENTIALS=${GOOGLE_APPLICATION_CREDENTIALS}
      - AZURE_STORAGE_ACCOUNT=${AZURE_STORAGE_ACCOUNT}
      - AZURE_STORAGE_KEY=${AZURE_STORAGE_KEY}
      
      # Cloud Storage Configuration
      - CLOUD_PROVIDER=azure
      - CLOUD_MODELS_CONTAINER=emprops-models
      - CLOUD_STORAGE_CONTAINER=emprops-share
      - CLOUD_STORAGE_TEST_CONTAINER=emprops-share-test
      - STORAGE_TEST_MODE=${STORAGE_TEST_MODE:-true}
      - SKIP_STORAGE_SYNC=${SKIP_STORAGE_SYNC:-true}
      # - STATIC_MODELS=${STATIC_MODELS}
      
      # Ollama (if enabled)
      - OLLAMA_HOST=${OLLAMA_HOST}
      - OLLAMA_DEFAULT_MODEL=${OLLAMA_DEFAULT_MODEL}
      
      # Simulation service configuration
      - SIMULATION_PORT=${SIMULATION_PORT:-8299}
      - SIMULATION_HOST=${SIMULATION_HOST:-localhost}
      - SIMULATION_PROCESSING_TIME=${SIMULATION_PROCESSING_TIME:-5}
      - SIMULATION_STEPS=${SIMULATION_STEPS:-10}
      - SIMULATION_FAILURE_RATE=${SIMULATION_FAILURE_RATE:-0.1}
      - SIMULATION_PROGRESS_INTERVAL_MS=${SIMULATION_PROGRESS_INTERVAL_MS:-500}
    
    # Port mapping (different from dev to avoid conflicts)
    ports:
      - "2229:22"      # SSH
      - "8089:80"      # HTTP
      - "3199:8188"    # ComfyUI GPU0
      - "3200:8189"    # ComfyUI GPU1 (if NUM_GPUS > 1)
      - "9099:9090"    # Health check
      - "8299:8299"    # Simulation service
    
    # No volume mounts - mimics ephemeral production machines
    # Everything runs from the Docker image like in production
    
    # Health check
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9090/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 120s  # Give time for worker download and custom nodes