# This file is dynamically generated by ./generate-docker-compose.sh
# Run the script to regenerate after changing environment variables

services:
  basic-machine:
    build:
      context: .
      dockerfile: Dockerfile
      args:
        CACHE_BUST: ${CACHE_BUST:-1}
        # Custom nodes build-time secrets
        CUSTOM_NODES_CACHE_BUST: ${CUSTOM_NODES_CACHE_BUST:-default}
        AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
        AWS_SECRET_ACCESS_KEY_ENCODED: ${AWS_SECRET_ACCESS_KEY_ENCODED}
        AWS_DEFAULT_REGION: ${AWS_DEFAULT_REGION}
        AZURE_STORAGE_ACCOUNT: ${AZURE_STORAGE_ACCOUNT}
        AZURE_STORAGE_KEY: ${AZURE_STORAGE_KEY}
        CLOUD_STORAGE_CONTAINER: ${CLOUD_STORAGE_CONTAINER}
        CLOUD_PROVIDER: ${CLOUD_PROVIDER}
        HF_TOKEN: ${HF_TOKEN}
        CIVITAI_TOKEN: ${CIVITAI_TOKEN}
        OLLAMA_HOST: ${OLLAMA_HOST}
        OLLAMA_PORT: ${OLLAMA_PORT}
        OLLAMA_DEFAULT_MODEL: ${OLLAMA_DEFAULT_MODEL}
        OPENAI_API_KEY: ${OPENAI_API_KEY}
    image: ${MACHINE_IMAGE:-basic-machine:latest}
    platform: linux/amd64
    container_name: ${MACHINE_CONTAINER_NAME:-basic-machine}
    hostname: ${MACHINE_CONTAINER_NAME:-basic-machine}
    restart: "no"  # Controlled by API instead of Docker
    
    # Fast shutdown for elastic scaling
    stop_grace_period: 2s
    stop_signal: SIGTERM
    
    # Environment variables - only what machine interface actually needs
    environment:
      # Docker/GPU runtime
      - NODE_ENV=production
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      
      # Machine identity and Redis connection (required)
      - MACHINE_ID=${MACHINE_ID}
      - MACHINE_CONTAINER_NAME=${MACHINE_CONTAINER_NAME}
      - HUB_REDIS_URL=${HUB_REDIS_URL}
      
      # Hardware configuration (required)
      - MACHINE_NUM_GPUS=${MACHINE_NUM_GPUS}
      - MACHINE_GPU_MEMORY_GB=${MACHINE_GPU_MEMORY_GB}
      - MACHINE_GPU_MODEL=${MACHINE_GPU_MODEL}
      
      # Service enablement flags (required)
      - MACHINE_ENABLE_COMFYUI=${MACHINE_ENABLE_COMFYUI}
      - MACHINE_ENABLE_REDIS_WORKERS=${MACHINE_ENABLE_REDIS_WORKERS}
      - MACHINE_ENABLE_SIMULATION=${MACHINE_ENABLE_SIMULATION}
      
      # Worker configuration (required)
      - WORKER_CONNECTORS=${WORKER_CONNECTORS}
      
      # Worker ComfyUI connection (for remote ComfyUI)
      - WORKER_COMFYUI_REMOTE=${WORKER_COMFYUI_REMOTE:-false}
      - WORKER_COMFYUI_HOST=${WORKER_COMFYUI_HOST:-localhost}
      - WORKER_COMFYUI_PORT=${WORKER_COMFYUI_PORT:-8188}
      - WORKER_COMFYUI_USERNAME=${WORKER_COMFYUI_USERNAME:-}
      - WORKER_COMFYUI_PASSWORD=${WORKER_COMFYUI_PASSWORD:-}
      
      # Optional configuration
      - WORKER_WEBSOCKET_AUTH_TOKEN=${WORKER_WEBSOCKET_AUTH_TOKEN:-}
      - MACHINE_ENABLE_NGINX=${MACHINE_ENABLE_NGINX:-false}
      - MACHINE_ENABLE_A1111=${MACHINE_ENABLE_A1111:-false}
      - MACHINE_ENABLE_OLLAMA=${MACHINE_ENABLE_OLLAMA:-false}
      - MACHINE_HEALTH_PORT=${MACHINE_HEALTH_PORT:-9090}
      - MACHINE_LOG_LEVEL=${MACHINE_LOG_LEVEL:-info}
      - MACHINE_TEST_MODE=${MACHINE_TEST_MODE:-false}
    
    # No volume mounts - use built-in ComfyUI installation from Docker image
    # volumes:
    #   - ./data:/workspace
    #   - ./data/logs:/workspace/logs
    #   - ./data/shared:/workspace/shared
      
    working_dir: /workspace
    
    # Resource limits based on environment
    deploy:
      resources:
        limits:
          memory: ${MEMORY_LIMIT:-8G}
        reservations:
          memory: ${MEMORY_RESERVATION:-2G}
